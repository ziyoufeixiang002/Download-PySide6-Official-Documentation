#!/bin/bash

# 设置变量
BASE_URLS=("https://kotlinlang.org/docs/" "https://kotlinlang.org/api/")
OUTPUT_DIR="kotlin_docs"
LINKS_FILE="kotlin_links.txt"

# 创建输出目录
mkdir -p $OUTPUT_DIR
cd $OUTPUT_DIR

echo "开始爬取 Kotlin 文档..."

# 使用 wget 递归爬取，但只获取链接
for url in "${BASE_URLS[@]}"; do
    echo "爬取: $url"
    
    # 使用 wget 递归下载，但限制深度和文件类型
    wget \
        --recursive \
        --level=10 \
        --no-parent \
        --page-requisites \
        --html-extension \
        --convert-links \
        --restrict-file-names=windows \
        --domains=kotlinlang.org \
        --reject="*.jpg,*.jpeg,*.png,*.gif,*.bmp,*.svg,*.ico" \
        --reject="*.mp3,*.wav,*.ogg,*.mp4,*.avi,*.mov,*.webm" \
        --reject="*.pdf,*.zip,*.tar,*.gz" \
        --timeout=30 \
        --tries=3 \
        --wait=1 \
        --random-wait \
        --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36" \
        "$url"
done

# 提取所有爬取到的链接
echo "提取链接..."
find . -type f -name "*.html" -exec grep -o 'href="[^"]*"' {} \; | \
    sed 's/href="//g' | sed 's/"$//g' | \
    grep -E '^https://kotlinlang.org/(docs|api)' | \
    grep -v -E '\.(jpg|jpeg|png|gif|bmp|svg|ico|mp3|wav|ogg|mp4|avi|mov|webm|pdf|zip|tar|gz)' | \
    sort -u > ../$LINKS_FILE

# 统计结果
LINK_COUNT=$(wc -l < ../$LINKS_FILE)
echo "爬取完成! 共找到 $LINK_COUNT 个链接"

# 清理下载的文件（我们只需要链接，不需要实际内容）
cd ..
rm -rf $OUTPUT_DIR

echo "结果已保存到: $LINKS_FILE"
